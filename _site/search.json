[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Carlos Llosa",
    "section": "",
    "text": "I obtained my M.S. and Ph.D. degrees in Statistics from Iowa State University in 2018 and 2022, respectively, and I received the B.S. degree in Mathematics from The University of Arizona in 2015. My doctoral dissertation was advised by Ranjan Maitra on the statistical analysis of tensor-valued data. Currently, I am a Senior Member of the Technical Staff at the Department of Statistical Sciences at Sandia National Laboratories in Albuquerque, NM. I am also an associate editor for Sankhya B, The Indian Journal of Statistics.\nMy main interest lies in the area of multilinear statistics, or the statistical analysis of tensor-valued data. This involves creating new models for tensor data, and also studying existing tensor models from a statistical perspective. More generally, I am interested in the statistical analysis of complex data structures, including functional, spatial, temporal, and tensor-variate data, particularly at the intersections of two or more of these domains.\n\n\n\n#My full CV will be available here.\nIowa State University Ames, IA\nPh.D. in Statistics | May 2018 - May 2022\nM.S. in Statistics | August 2016 - May 2018\nThe University of Arizona Tucson, AZ\nB.S. in Mathematics | August 2011- May 2015\n\n\n\nCarlos Llosa\nStatistical Sciences\nSandia National Laboratories\nPO Box 5800 MS 0829\nAlbuquerque, NM 87185\nEmail SNL: cjllosa@sandia.gov\nPhone: 505-844-2540"
  },
  {
    "objectID": "papers.html#section",
    "href": "papers.html#section",
    "title": "Carlos Llosa",
    "section": "2025",
    "text": "2025\nOscar López, Arvind Prasadan, Carlos Llosa-Vite, Richard B. Lehoucq, Daniel M. Dunlavy, “Near-Efficient and Non-Asymptotic Multiway Inference”, arXiv:2511.05368\nCarlos Llosa-Vite, Daniel M. Dunlavy, Richard B. Lehoucq, Oscar López, Arvind Prasadan, “A Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model: Maximum Likelihood Estimation and Fisher Information”, arXiv:2511.05352"
  },
  {
    "objectID": "papers.html#section-1",
    "href": "papers.html#section-1",
    "title": "Carlos Llosa",
    "section": "2024",
    "text": "2024\nCarlos Llosa-Vite, Ranjan Maitra, “Elliptically-Contoured Tensor-variate Distributions with Application to Image Learning”, ACM Transactions on Probabilistic Machine Learning, 1.1, 2024. DOI (A version of this manuscript was Runners’-up at the Statistical Methods in Imaging Student Paper Competition award)\nJason Adams, Brandon Berman, Thomas Buchheit, Carlos Llosa, Shahed Reza, “Recent Advances in Functional Data Analysis for Electronic Device Data”, 2024 8th IEEE Electron Devices Technology & Manufacturing Conference (EDTM), 2024. DOI"
  },
  {
    "objectID": "papers.html#section-2",
    "href": "papers.html#section-2",
    "title": "Carlos Llosa",
    "section": "2022",
    "text": "2022\nCarlos Llosa-Vite, Ranjan Maitra, “Reduced-rank tensor-on-tensor regression and tensor-variate analysis of variance”, IEEE Transactions on Pattern Analysis and Machine Intelligence, 45.2, 2024. DOI (A version of this manuscript won me the first-place award at the 2022 Student Paper Competition of the ASA Section on Statistics in Imaging.)\nBishoy Dawood, Carlos Llosa-Vite, Geoffrey Z. Thompson, Barbara K. Lograsso, Lauren K. Claytor, John Vanderkolk, William Meeker, Ranjan Maitra, Ashraf Bastawros, “Quantitative matching of forensic evidence fragments utilizing 3D microscopy analysis of fracture surface replicas”, Journal of Forensic Sciences, 67.3, 2022. DOI"
  },
  {
    "objectID": "papers.html#section-3",
    "href": "papers.html#section-3",
    "title": "Carlos Llosa",
    "section": "2018",
    "text": "2018\nCarlos Llosa, “Tensor on tensor regression with tensor normal errors and tensor network states on the regression parameter”, Creative components, Iowa State Digital Repository, 2018. PDF"
  },
  {
    "objectID": "papers.html#section-4",
    "href": "papers.html#section-4",
    "title": "Carlos Llosa",
    "section": "2025",
    "text": "2025\n\n(contributed poster) “The Generalized Multilinear Model” Statistics Meets Tensors: Methodology, Theory, and Applications, May 6, 2025, Poster\n(invited talk) “Poisson-response Tensor-on-Tensor Regression and Applications” ASA Statistics in Imaging Virtual Working Group Colloquium, February 27, 2025, Slides\n(contributed poster) “On a Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model” 2025 Conference on Data Analysis (CoDA2025), February 26, 2025"
  },
  {
    "objectID": "papers.html#section-5",
    "href": "papers.html#section-5",
    "title": "Carlos Llosa",
    "section": "2024",
    "text": "2024\n\n(contributed talk) “Elliptically-Contoured Tensor-Variate Distributions” 2024 IMS International Conference on Statistics and Data Science (ICSDS 2024), December 18, 2024, Slides\n(invited talk) “Elliptically-Contoured Tensor-Variate Distributions” 18th International Joint Conference on Computational and Financial Econometrics (CFE) and Computational and Methodological Statistics (CMStatistics 2024), December 14, 2024, Slides\n(contributed poster) “On a Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model” SIAM Conference on Mathematics of Data Science (MDS24), October 21, 2024\n(invited talk) “Probabilistic Guarantees for Low-Rank Tensor Decompositions” The 2024 Sandia Machine Learning and Deep Learning (MLDL24) Workshop , September 11, 2024, Slides\n(contributed talk) “On a Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model” 2024 Joint Statistical Meetings (JSM 2024), August 7, 2024, Slides"
  },
  {
    "objectID": "papers.html#section-6",
    "href": "papers.html#section-6",
    "title": "Carlos Llosa",
    "section": "2023",
    "text": "2023\n\n(invited talk) “On a Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model” 16th International Conference of the ERCIM WG on Computational and Methodological Statistics (CMStatistics 2023) , December 17, 2023, Slides\n(invited talk) “Poisson-response Tensor-on-Tensor Regression and Applications” Iowa State University Department of Statistics 75th Anniversary Research Conference, October 1, 2023, Slides\n(contributed talk) “Poisson-response Tensor-on-Tensor Regression and Applications” 2023 Joint Statistical Meetings (JSM 2023), August 7, 2023, Slides\n(invited talk) “Poisson-response Tensor-on-Tensor Regression and Applications” The 2023 Sandia Machine Learning and Deep Learning (MLDL23) Workshop , July 4, 2023, Slides\n(contributed poster) “Poisson-response Tensor-on-Tensor Regression and Applications” 2023 Conference on Data Analysis (CoDA2023), March 8, 2023"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Carlos Llosa",
    "section": "",
    "text": "Research\nMy primary research focus lies in extending traditional statistical models to accommodate tensor data. This endeavor often involves navigating a vast parameter space, which I aim to reduce through the application of low-rank tensor factorizations. As a motivating example, consider the following matrix-response, matrix-covariate linear regression model:\n\nY_i = X_i \\cdot \\beta + E_i\n\nHere, Y_i is a matrix of size M_1 \\times M_2 and X_i is a matrix of size N_1 \\times N_2. This formulation introduces two tensor parameters:\n\nThe coefficient \\beta, represented as a 4D tensor of size M_1 \\times M_2 \\times N_1 \\times N_2.\nThe covariance matrix of the error term E_i, denoted as \\Sigma, which is another 4D tensor of size M_1 \\times M_1 \\times M_2 \\times M_2.\n\nThe large number of parameters above renders inference for traditional linear regression impractical, particularly without a sufficiently large sample size. To address this challenge, it is common to impose restrictions on the parameter space. Standard approaches include regularization techniques such as Lasso and Ridge regression for \\beta, and Graphical Lasso for \\Sigma. However, these methods often overlook the rich tensor structure that could facilitate more effective parameter-space restrictions.\nIn my research, I typically assume that while \\beta and \\Sigma are large, they can be characterized by a significantly smaller number of coefficients, through a specified low-rank tensor factorization. I have published work exploring the use of canonical polyadic (CP), Tucker, and tensor train/ring factorizations for the coefficient \\beta. Additionally, I have investigated the case where \\Sigma can be represented as a large Kronecker product. Low-rank assumptions on \\Sigma are more challenging due to symmetry and positive definiteness, and it is also one of my research interests.\nAnother avenue of my research seeks to extend the traditional additive-error Gaussian-noise framework I described in the above linear regression setup. A core objective of my work is to enable practitioners of conventional statistical methodologies—such as ANOVA, Poisson regression, discriminant analysis, Gaussian mixtures, logistic regression, and generalized linear models (GLMs)—to effectively transfer their expertise into the realm of tensor analysis.\nFurthermore, I also work on framing existing tensor methods as statistical models and deriving fundamental statistical properties from them. This includes investigating the conditions under which these models are well-posed (identifiable), analyzing the Fisher Information Matrix, and exploring its utility in bounding estimation errors. In addition to traditional Cramér-Rao bounds, I have also contributed to the development of probability bounds and minimax error bounds.\nDuring my PhD, I was particularly motivated by applications involving image data. Since then, I have encountered tensors of various forms and distributions, including count time-series tensors derived from dyadic data, moment tensors from multivariate datasets, count tensors from multivariate histograms, adjacency tensors from multigraphs, and hyperspectral imaging tensors. The ubiquity of tensors in diverse fields inspires me to continue pursuing this field of research.\n\n\n\n\n\n\nSandia Statistical Sciences"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Carlos Llosa",
    "section": "",
    "text": "Resume\n\nResearch Interests\nStatistical Tensor Analysis, Tensor decompositions, Statistical Learning, Medical Imaging, Image Analysis, Dyadic Data Analysis, Computational Statistics, Forensic Matching\n\n\nEducation\nDoctor of Philosophy in Statistics (2022)\nIowa State University, Ames, IA\nThesis title: Statistical methods for tensor-valued data\nThesis advisor: Prof. Ranjan Maitra\nMaster of Science in Statistics (2018)\nIowa State University, Ames, IA\nCreative Component title: Tensor on tensor regression with tensor normal errors and tensor network states on the regression parameter PDF\nThesis advisor: Prof. Ranjan Maitra\nBachelor of Science in Mathematics (2015)\nThe University of Arizona, Tucson, AZ\n\n\nExperience\nSenior Member of Technical Staff (2022-present)\nSandia National Laboratories\nStatistical Sciences\nAlbuquerque, NM\nResearch Assistant (2019-2022)\nStatistical Analysis of Forensic Evidence Imaging Iowa State University, Ames, IA\nTeaching Assistant (2016-2019)\nBusiness Statistics Instructor\nIowa State University, Ames, IA\n\n\nAffiliations\nASA, SIAM, ACM, IEEE"
  },
  {
    "objectID": "software.html#totr",
    "href": "software.html#totr",
    "title": "Carlos Llosa",
    "section": "totr",
    "text": "totr\nI’m lead author of the totr R package (GitHub).\nThis package performs Gaussian linear regression with tensor responses and tensor covariates. This implementation allows modeling the entry-to-entry correlation in the response tensor, and allows for four different types of low-rank regression coefficients."
  },
  {
    "objectID": "papers.html#section-7",
    "href": "papers.html#section-7",
    "title": "Carlos Llosa",
    "section": "2022",
    "text": "2022\n\n(invited talk, first place in student paper competition) “Reduced-Rank Tensor-on-Tensor Regression and Tensor-Variate ANOVA” 2022 Joint Statistical Meetings (JSM 2022), August 7, 2022, Slides\n(invited talk, runner-up in student paper competition) “Tensor-variate elliptically contoured distributions with application to image learning” The 2022 Statistical Methods in Imaging (SMI) Conference, May 25, 2022, Slides\n(invited talk) “Reduced-Rank Tensor-on-Tensor Regression and Tensor-Variate ANOVA” Iowa State University Department of Statistics Seminar, February, 2022, Slides"
  }
]